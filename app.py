from dotenv import load_dotenv
load_dotenv()
import streamlit as st
from dotenv import load_dotenv
import os

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

openai_api_key = st.secrets["OPENAI_API_KEY"]

# LLM ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆ
chat = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7, api_key=openai_api_key)

# å°‚é–€å®¶ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
expert_prompts = {
    "æ–™ç†ã®å°‚é–€å®¶": "ã‚ãªãŸã¯ä¸€æµã®æ–™ç†ç ”ç©¶å®¶ã§ã™ã€‚å®¶åº­æ–™ç†ã‹ã‚‰ãƒ—ãƒ­ã®æŠ€ã¾ã§è©³ã—ãã€è¦ªåˆ‡ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
    "é‡‘èã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼": "ã‚ãªãŸã¯ä¿¡é ¼ã§ãã‚‹é‡‘èã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚æŠ•è³‡ã€è²¯é‡‘ã€å®¶è¨ˆç®¡ç†ãªã©ã«çš„ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚",
    "å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼": "ã‚ãªãŸã¯æ¸©ã‹ãè©±ã‚’èã„ã¦ãã‚Œã‚‹å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚å¿ƒã«å¯„ã‚Šæ·»ã£ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚"
}

# å›ç­”é–¢æ•°
def ask_expert(user_input, role):
    messages = [
        SystemMessage(content=expert_prompts[role]),
        HumanMessage(content=user_input)
    ]
    response = chat(messages)
    return response.content

# --- Streamlit ã‚¢ãƒ—ãƒªã®UI ---

st.title("ğŸ’¬ å°‚é–€å®¶ã«èã„ã¦ã¿ã‚ˆã† - LLMã‚¢ãƒ—ãƒª")
st.write("ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ã‚’å…¥åŠ›ã—ã€ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§è©±ã—ãŸã„å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚LLMãŒå°‚é–€å®¶ã«ãªã‚Šãã£ã¦å›ç­”ã—ã¾ã™ã€‚")

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼šå°‚é–€å®¶ã®é¸æŠ
role = st.radio("ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„", list(expert_prompts.keys()))

# ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("é€ä¿¡"):
    if user_input:
        with st.spinner("å°‚é–€å®¶ãŒå›ç­”ä¸­ã§ã™..."):
            answer = ask_expert(user_input, role)
            st.success("å›ç­”ï¼š")
            st.write(answer)
    else:
        st.warning("è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

